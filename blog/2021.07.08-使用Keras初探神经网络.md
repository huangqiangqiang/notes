# 初探 Keras 深度学习框架

上一篇，我们了解了神经网络的原理，现在，我们就用 Keras 来做一个实际的项目 - 猫狗分类器。

为什么要使用 Keras 呢，因为 Keras 比较主流，遇到问题比较好查。

我们可以在百度 AI studio 官网上面寻找训练集，官方专门有一栏 数据集的导航，里面有很多类型的数据集。找到[猫狗训练集](https://aistudio.baidu.com/aistudio/datasetdetail/23234)，

猫狗的数据集下载好后，我们还要进行一些前期的准备工作。

# 准备适合于 Keras 的数据集

Keras 规定的目录结构如下图，这样 Keras 就能知道有几个分类和对应分类下的图片了。

```
--- CatAndDog
|- test
  |- cat
  |- dog
|- validation
  |- cat
  |- dog
|- train
  |- cat
  |- dog
```

# 开始构建模型

先贴上全部代码，再详细说每个值得注意的地方。

```
# CatDogClassifier.py

#!/usr/bin/python
# -*- coding: UTF-8 -*-

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense, Conv2D, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing import image
from tensorflow.python.keras.layers.core import Flatten
import os, sys, getopt
import matplotlib.pyplot as plt
import numpy as np

class CatDogClassifier:
  """猫狗分类器

  提高训练准确度的方法：
  1. 增强数据，并添加 Dropout 层
  2. 提供验证集
  3. 迁移学习
  """

  model_filename = 'CatDogClassifier_model.h5'

  def __init__(self):
    self.model = self.createModel()

  def load_data(self, train_directory):
    train_datagen = image.ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest'
    )
    val_datagen = image.ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(train_directory + '/train', target_size=(150, 150), batch_size=32, class_mode='binary')
    val_generator = val_datagen.flow_from_directory(train_directory + '/val', target_size=(150, 150), batch_size=32, class_mode='binary')
    
    print(train_generator.class_indices)
    return train_generator, val_generator


  def createModel(self):
    model = Sequential()
    model.add(Conv2D(filters=32 , kernel_size=(3,3), activation='relu', input_shape=(150, 150, 3)))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(filters=64 , kernel_size=(3,3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(filters=128 , kernel_size=(3,3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(filters=128 , kernel_size=(3,3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))

    model.summary()
    return model

  def train(self, train_directory):
    """训练，根据训练目录开始训练.

    Args:
        train_directory: 训练的路径
    """
    print('start training..., train directory:', train_directory)
    train_generator, val_generator = self.load_data(train_directory)

    model = self.model
    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
    history = model.fit_generator(train_generator, epochs=30, validation_data=val_generator)
    model.save_weights(CatDogClassifier.model_filename)
    self.showHistory(history.history)

  def showHistory(self, history):
    epochs = range(1, len(acc) + 1)
    loss = history['loss']
    acc = history['acc']
    val_loss = history['val_loss']
    val_acc = history['val_acc']
    
    self.showAcc(epochs, acc, val_acc)
    self.showLoss(epochs, loss, val_loss)

  def showAcc(self, epochs, acc, val_acc):
    plt.plot(epochs, acc, 'bo', label='Training acc')
    plt.plot(epochs, val_acc, 'b', label='Validation acc')
    plt.title('acc')
    plt.legend()
    plt.show()

  def showLoss(self, epochs, loss, val_loss):
    plt.plot(epochs, loss, 'bo', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('loss')
    plt.legend()
    plt.show()

  def predict(self, predict_image_path):
    """预测，根据图片地址预测类别.

    Args:
        predict_image_path: 预测的图片路径
    """

    img = image.load_img(predict_image_path, target_size=(150, 150))
    img_tensor = image.img_to_array(img)
    img_tensor = np.expand_dims(img_tensor, axis=0)
    img_tensor /= 255.

    self.model.load_weights(CatDogClassifier.model_filename)
    self.model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
    pred = self.model.predict_classes(img_tensor)
    if pred[0]:
      print(pred[0])
    # print(pred.argmax())


  def predict_batch(self, predict_image_batch):
    """预测，根据图片地址预测类别.

    Args:
        predict_image_batch: 批量预测
    """
    imgs = []
    for image_path in predict_image_batch:
      img = image.load_img(image_path, target_size=(150, 150))
      img_tensor = image.img_to_array(img)
      img_tensor = np.expand_dims(img_tensor, axis=0)
      img_tensor /= 255.
      imgs.append(img_tensor)

    imgs = np.concatenate([x for x in imgs])

    print(imgs.shape)

    self.model.load_weights(CatDogClassifier.model_filename)
    self.model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
    pred = self.model.predict(imgs)
    pred2 = self.model.predict_classes(imgs)
    print(pred, pred2)


def main(argv):
   inputfile = ''
   inputDirectory = ''
   try:
      opts, args = getopt.getopt(argv, "hf:d:", ['file=', 'directory='])
   except getopt.GetoptError:
      print('CatDogClassifier.py -f <inputfile> or CatDogClassifier.py -d <directory>')
      sys.exit(2)
   for opt, arg in opts:
      if opt == '-h':
        print('CatDogClassifier.py -f <inputfile> or CatDogClassifier.py -d <directory>')
        sys.exit()
      elif opt in ("-f", "--file"):
         inputfile = arg
      elif opt in ("-d", "--directory"):
         inputDirectory = arg
   return inputfile, inputDirectory

if __name__ == '__main__':
  inputfile, inputDirectory = main(sys.argv[1:])
  classifier = CatDogClassifier()
  if inputfile:
    print('--------------------> input file:', inputfile)
    classifier.predict(inputfile)
  elif inputDirectory:
    print('--------------------> input directory:', inputDirectory)
    g = os.walk(inputDirectory)
    for path, dir_list, file_list in g:
      ps = []
      for file_name in file_list:
        ps.append(os.path.join(path, file_name))
      classifier.predict_batch(ps)
  else:
    print('--------------------> train')
    classifier.train('./dataset/cat_vs_dog')
```

先说一下 `CatDogClassifier.py` 文件的用法。全部的实现都在这个 `CatDogClassifier.py` 文件里面，第一次执行的时候直接执行 `python CatDogClassifier.py` 命令，就会开始训练，训练完毕后会在当前目录生成一个 CatDogClassifier_model.h5 文件，是调用模型的 load_weight 方法生成的，我们知道，训练神经网络就是让参数去拟合训练集，load_weight 这个方法就是保存训练好的权重。对应还有一个 save 方法是保存整个模型，包含了权重和模型层级的结构。

`CatDogClassifier.py` 接受 -d 和 -f 两个参数，-d（--directory） 需要传一个目录，会预测这个目录下的所有文件，-f（--file）表示预测单张图片。

```
python CatDogClassifier.py -f dataset/test/1.jpg
```

# 代码解析

### 载入数据
了解了 `CatDogClassifier.py` 脚本的用法后，我们详细说说上面代码的含义和遇到的坑。

首先，程序的入口是 `if __name__ == '__main__'`，我们实例化了 CatDogClassifier 类并调用 train 方法。

在 train 方法中，我们首先调用了 load_data 方法，这个方法返回了 train_generator 和 val_generator， generator 是 keras 的一个概念，后面在拟合数据的时候就是从 generator 里面去批量的获取数据的，因为几万张图片不可能一次性载入到内存中，只能一个 batch 一个 batch 的获取，而且 generator 还能进行数据增强，就是对 图片数据进行随机的旋转，缩放，平移，翻转等操作，数据增强的代码如下：
```
train_datagen = image.ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
```

这里需要注意的是，我们只能对训练集进行数据增强，而不能对验证集进行增强。

后面在生成 generator 时调用的参数指定了多少张图片为一个批次（batch_size），因为我们是二分类，所以 class_mode 为 binary，这个参数会影响对应的 label 标签，所以是哪种分类一定要填对。

```
train_generator = train_datagen.flow_from_directory(train_directory + '/train', target_size=(150, 150), batch_size=32, class_mode='binary')
```

load_data 之后是 createModel，创建模型。模型创建好后可以调用 model.summary() 查看模型的摘要，我这边使用的是 4 层卷积池化层+全连接层，摘要信息如下：

```
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 148, 148, 32)      896       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 5, 5, 256)         295168    
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
flatten (Flatten)            (None, 1024)              0         
_________________________________________________________________
dropout (Dropout)            (None, 1024)              0         
_________________________________________________________________
dense (Dense)                (None, 512)               524800    
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 513       
=================================================================
Total params: 1,061,313
Trainable params: 1,061,313
Non-trainable params: 0
```

model 中的每一层都有名字。
第一列的 Layer (type) 就是显示的层的名称。
第二列 Output Shape 表示当前层的输出形状，因为我们的输入层为 (x, 150，150, 3)，x 为数据集的大小，经过卷积层之后由于卷积层的性质，高宽会减少 2，由于第一次有 32 个过滤器，所以输出的形状为 (148, 148, 32)。
第三列 Param 表示的是当前层的权重个数，表示当前层有多少个参数需要训练。第一层有 896 个参数需要训练。这个数字是怎么得来的呢？公式：32 * (3 * (3*3) + 1) == 896，32个过滤器，每个过滤器高宽都为 3，有 3 个通道，最后 +1 是因为存在偏置。

模型的构建我在实战的过程中也总结出了一些经验。

模型构建好了，接下来调用 compile 方法编译模型，一般就那么几类参数，如果是猫狗二分类问题的话，固定这么写就可以了

```
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
```

接下来就是训练模型了，调用 fit_generator 方法，把 generator 传进去。

```
history = model.fit_generator(train_generator, epochs=30, validation_data=val_generator)
```

fit_generator 是实际开始训练模型的方法，我们的代码会阻塞在这一行， fit_generator 这个方法第一个参数就是传入 train_generator， epochs 代表训练的轮数，训练集中所有的图片都遍历一次算一轮（这个说法不准确，实际上还有一个 steps_per_epoch 参数来控制多少算一轮，除非你不想用到所有的训练集才设置这个值），这里我们训练 30 轮。validation_data 这个参数传入验证集，每训练完一轮就会拿当前状态的模型跑一遍验证集，把结果给记录下来，存到 history 变量里。

history 变量保存每一轮的 loss 和 acc 的值，方便我们分析。

最后，我们调用 showAcc 和 showLoss 函数把这 30 轮的训练过程通过图表的形式展现出来。

# 分析 history

<div align="center"><img width="500px" src="./2021.07.08/acc.png"/></div>

<div align="center"><img width="500px" src="./2021.07.08/loss.png"/></div>

上面一张表示预测的准确度。原点表示在训练集中的预测精确度，折线表示在验证集中的精确度。从图中可以看到，经过长时间的训练，模型在训练集中的精确度一直在提高，但是在验证集中的准确度却没有提高，在训练到 7-8 轮的时候差不多就已经到达峰值了，也就是说，在 7-8 轮之前，模型是欠拟合的，7-8 轮之后，模型过拟合了，所以，我们可以把 epoch 参数从 30 改为 7 就可以了。这就是验证集的作用，指导我们调节超参数。

从第二张图中的损失值中，我们也可以得出相同的结论，这里就不再说明了。