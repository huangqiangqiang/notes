# 搭建 kafka 服务

项目中使用 kafka 做为数据源，所以内网要搭建一个 kafka 做测试。因为对 kafka 不是很了解，还是花了蛮多时间的。这里几个笔记。

## kafka 配置中的 ssl 和 sasl 是什么？

ssl 类似 https 中的 ssl，作用是一样的， ssl 的作用是把传输的信息加密。

sasl 的作用就是用户名密码验证，只是在建立连接的时候一次性验证。

## broker 指的是什么
docker-compose 中 zookeeper 和 kafka 两个服务，也有人把 kafka 叫做 broker。

## listeners 和 advertised listeners 有什么区别

listeners 用作内部访问，advertised_listeners用作外部访问。

比如在阿里云上部署了一个 kafka，那么 advertised_listeners 填的就是阿里云服务器的外网ip和端口，listeners填的内部的ip和端口

## 搭建无 sasl 验证的 kafka 服务

docker-compose.yml
```
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181"
    restart: always

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 192.168.0.2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_PORT: 9092
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - "zookeeper"
    restart: always
```

理论上直接 docker-compose up -d 就能直接用了，但是实际中我发现内网会报错

```
xxx Connection to node 1001 (xxx) could not be established. Broker may not be availabel.
```

这个报错的意思是连接补上 kafka 服务，我对这个报错很奇怪，为什么 kafka 服务自己会报连不上自己的错。只能进行一些猜测，连接自己的话他可能是通过宿主机的端口连接自己，我这边内网默认情况下容器内不能访问宿主机的，所以我把防火墙开起来就可以了。

之后就用官方提供的bin目录中的脚本测试就可以了。

## 搭建 sasl 验证的 kafka 服务

```
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181"
    restart: always

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: SASL_PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://192.168.0.2:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf"
      KAFKA_INTER_BROKER_LISTENER_NAME: SASL_PLAINTEXT
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf
    depends_on:
      - "zookeeper"
    restart: always
```

另外创建一个 kafka_server_jaas.conf 文件：

```
KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username="admin"
  password="admin-secret"
  user_admin="admin-secret"
  user_alice="alice-secret";
};
Client {};
```

这样就启用了 sasl 验证。

## cli 脚本支持 sasl

需要添加一个配置文件，比如创建一个 file.properties

```
security.protocol=SASL_PLAINTEXT
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="admin" \
  password="admin-secret";
```

注意最后的分号要写上。

在cli 指定这个配置文锦啊就可以连上了

消费者例子：
```
./kafka-console-consumer.sh --topic t --bootstrap-server 192.168.0.2:9092 --consumer.config /path/to/file.properties
```

生产者例子：
```
./kafka-console-producer.sh --topic t --bootstrap-server 192.168.0.2:9092 --producer.config /path/to/file.properties
```
